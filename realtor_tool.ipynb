{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c61757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 7809.854010850651\n",
      "Predicted Rent: 35433.136530941745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Define features and target\n",
    "features = ['Location', 'No. of Bedroom', 'Parking', 'Furnishing Status', 'Gated Security', 'Total SqFt', 'Age of Building']\n",
    "target = 'Rent'\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Handle missing values in features\n",
    "numeric_features = ['Total SqFt', 'Age of Building']\n",
    "categorical_features = ['Location', 'No. of Bedroom', 'Parking', 'Furnishing Status', 'Gated Security']\n",
    "\n",
    "# Define preprocessor with imputation and one-hot encoding for categorical features\n",
    "numeric_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the Gradient Boosting model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_rent(input_data):\n",
    "    return pipeline.predict(input_data)\n",
    "\n",
    "# Example prediction\n",
    "example_input = pd.DataFrame({\n",
    "    'Location': ['HSR Layout'],\n",
    "    'No. of Bedroom': ['2 Bedroom'],\n",
    "    'Parking': ['Bike and Car'],\n",
    "    'Furnishing Status': ['Fully Furnished'],\n",
    "    'Gated Security': ['Yes'],\n",
    "    'Total SqFt': [1200],\n",
    "    'Age of Building': [5]\n",
    "})\n",
    "\n",
    "predicted_rent = predict_rent(example_input)\n",
    "print(f'Predicted Rent: {predicted_rent[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ec79b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['Age of Building', 'Water Supply', 'Rent', 'Transit Score',\n",
      "       'Smoking Allowed', 'Location', 'Bathroom', 'Non-Veg Allowed',\n",
      "       'Posted On', 'Parking', 'Property Type', 'Furnishing Status',\n",
      "       'No. of Bedroom', 'Facing', 'Gated Security', 'Deposit',\n",
      "       'Attached Bathroom', 'Livability Score', 'Balcony', 'URL',\n",
      "       'Drinking Allowed', 'Possession', 'Total SqFt', 'AC', 'Floor',\n",
      "       'Preferred Tenant', 'Room Type'],\n",
      "      dtype='object')\n",
      "Numeric features: ['Age of Building', 'Transit Score', 'Bathroom', 'Deposit', 'Livability Score', 'Total SqFt']\n",
      "Categorical features: ['Water Supply', 'Smoking Allowed', 'Location', 'Non-Veg Allowed', 'Posted On', 'Parking', 'Property Type', 'Furnishing Status', 'No. of Bedroom', 'Facing', 'Gated Security', 'Attached Bathroom', 'Balcony', 'URL', 'Drinking Allowed', 'Possession', 'AC', 'Floor', 'Preferred Tenant', 'Room Type']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: ['Smoking Allowed' 'Attached Bathroom' 'Drinking Allowed' 'AC' 'Room Type']. At least one non-missing value is needed for imputation with strategy='most_frequent'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 6125.241901979707\n",
      "Predicted Rent: 29749.76631694349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: ['Smoking Allowed' 'Attached Bathroom' 'Drinking Allowed' 'AC' 'Room Type']. At least one non-missing value is needed for imputation with strategy='most_frequent'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: ['Smoking Allowed' 'Attached Bathroom' 'Drinking Allowed' 'AC' 'Room Type']. At least one non-missing value is needed for imputation with strategy='most_frequent'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#### final gradient boosting\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Define all features except 'Rent' and the target variable 'Rent'\n",
    "features = df.columns.drop(['Rent'])  # Ensure 'Rent' is not included as a feature\n",
    "target = 'Rent'\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Print columns to ensure consistency\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Handle missing values in features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Print out the features being used\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "# Define preprocessor with imputation and one-hot encoding for categorical features\n",
    "numeric_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the Gradient Boosting model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Function to make predictions with flexible input\n",
    "def predict_rent(input_data):\n",
    "    # Convert input data to DataFrame, fill missing columns with NaNs\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    missing_cols = [col for col in features if col not in input_df.columns]\n",
    "    for col in missing_cols:\n",
    "        input_df[col] = [None]\n",
    "    \n",
    "    # Reorder columns to match the training data\n",
    "    input_df = input_df[features]\n",
    "    \n",
    "    # Predict using the trained pipeline\n",
    "    return pipeline.predict(input_df)\n",
    "\n",
    "# Example prediction with flexible input\n",
    "example_input = {\n",
    "    'Location': ['HSR Layout'],\n",
    "    'No. of Bedroom': ['2 Bedroom'],\n",
    "    'Parking': ['Bike and Car'],\n",
    "    'Furnishing Status': ['Fully Furnished'],\n",
    "    'Total SqFt': [1200]\n",
    "    # You can omit or add any feature; the model will handle it\n",
    "}\n",
    "\n",
    "predicted_rent = predict_rent(example_input)\n",
    "print(f'Predicted Rent: {predicted_rent[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9689c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of predictions with error < 1000: 72.07%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test)\n",
    "\n",
    "# Calculate the percentage of predictions with an error margin of less than 1000\n",
    "percentage_within_1000 = (errors < 6000).mean() * 100\n",
    "\n",
    "print(f'Percentage of predictions with error < 1000: {percentage_within_1000:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "931c7e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 4s 10ms/step - loss: 13214.9619 - val_loss: 6753.1968\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "Mean Absolute Error: 8523.488961658226\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted Rent: 10980.6396484375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Define all features except 'Rent' and the target variable 'Rent'\n",
    "features = df.columns.drop(['Rent'])  # Ensure 'Rent' is not included as a feature\n",
    "target = 'Rent'\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Handle missing values in features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Define preprocessor with imputation, scaling, and one-hot encoding\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Convert directly to dense\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert to dense array if it's still sparse\n",
    "X = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Convert y_train to a NumPy array\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1, validation_split=0.2, batch_size=10, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Function to make predictions with flexible input using the trained model\n",
    "def predict_rent(input_data):\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    missing_cols = [col for col in features if col not in input_df.columns]\n",
    "    for col in missing_cols:\n",
    "        input_df[col] = [None]\n",
    "    \n",
    "    input_df = preprocessor.transform(input_df)\n",
    "    input_df = input_df.toarray() if hasattr(input_df, 'toarray') else input_df\n",
    "    return model.predict(input_df).flatten()[0]\n",
    "\n",
    "# Example prediction with flexible input\n",
    "example_input = {\n",
    "    'Location': ['HSR Layout'],\n",
    "    'No. of Bedroom': ['2 Bedroom'],\n",
    "    'Parking': ['Bike and Car'],\n",
    "    'Furnishing Status': ['Fully Furnished'],\n",
    "    'Total SqFt': [1000]\n",
    "}\n",
    "\n",
    "predicted_rent = predict_rent(example_input)\n",
    "print(f'Predicted Rent: {predicted_rent}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd851658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted Rent: 19797.6328125\n"
     ]
    }
   ],
   "source": [
    "# Example prediction with flexible input\n",
    "example_input = {\n",
    "    'Location': ['HSR Layout'],\n",
    "    'No. of Bedroom': ['2 Bedroom'],\n",
    "    'Parking': ['Bike and Car'],\n",
    "    'Furnishing Status': ['Fully Furnished'],\n",
    "    'Total SqFt': [1000]\n",
    "}\n",
    "\n",
    "predicted_rent = predict_rent(example_input)\n",
    "print(f'Predicted Rent: {predicted_rent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71ab95bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3138/3138 [==============================] - 24s 7ms/step - loss: 7948.6738 - val_loss: 5389.4307\n",
      "Epoch 2/15\n",
      "3138/3138 [==============================] - 25s 8ms/step - loss: 5899.7266 - val_loss: 5412.5781\n",
      "Epoch 3/15\n",
      "3138/3138 [==============================] - 27s 8ms/step - loss: 5656.9146 - val_loss: 4927.9150\n",
      "Epoch 4/15\n",
      "3138/3138 [==============================] - 26s 8ms/step - loss: 5369.5967 - val_loss: 5069.0518\n",
      "Epoch 5/15\n",
      "3138/3138 [==============================] - 26s 8ms/step - loss: 5207.0059 - val_loss: 4909.3379\n",
      "Epoch 6/15\n",
      "3138/3138 [==============================] - 27s 8ms/step - loss: 4893.5820 - val_loss: 4928.6890\n",
      "Epoch 7/15\n",
      "3138/3138 [==============================] - 26s 8ms/step - loss: 4917.5742 - val_loss: 4860.1279\n",
      "Epoch 8/15\n",
      "3138/3138 [==============================] - 26s 8ms/step - loss: 4890.0957 - val_loss: 4930.7339\n",
      "Epoch 9/15\n",
      "3138/3138 [==============================] - 27s 9ms/step - loss: 4521.2446 - val_loss: 4885.2310\n",
      "Epoch 10/15\n",
      "3138/3138 [==============================] - 28s 9ms/step - loss: 4333.1055 - val_loss: 4873.1333\n",
      "Epoch 11/15\n",
      "3138/3138 [==============================] - 28s 9ms/step - loss: 4312.2793 - val_loss: 4939.8721\n",
      "Epoch 12/15\n",
      "3138/3138 [==============================] - 28s 9ms/step - loss: 4243.4189 - val_loss: 4925.6909\n",
      "Epoch 13/15\n",
      "3138/3138 [==============================] - 27s 9ms/step - loss: 4023.6892 - val_loss: 5056.0601\n",
      "Epoch 14/15\n",
      "3138/3138 [==============================] - 28s 9ms/step - loss: 3977.6440 - val_loss: 4959.9458\n",
      "Epoch 15/15\n",
      "3138/3138 [==============================] - 28s 9ms/step - loss: 3917.3081 - val_loss: 5922.9097\n",
      "31/31 [==============================] - 0s 5ms/step\n",
      "Mean Absolute Error: 6804.783410432992\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Predicted Rent: 14925.326171875\n"
     ]
    }
   ],
   "source": [
    "### better neural net approach-currently testing\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Define all features except 'Rent' and the target variable 'Rent'\n",
    "features = df.columns.drop(['Rent'])  # Ensure 'Rent' is not included as a feature\n",
    "target = 'Rent'\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Handle missing values in features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Define preprocessor with imputation, scaling, and one-hot encoding\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Convert directly to dense\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert to dense array if it's still sparse\n",
    "X = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Convert y_train to a NumPy array\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Define the neural network model with adjusted learning rate\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model with a custom learning rate\n",
    "learning_rate = 0.001  # Adjust this value to optimize training\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "\n",
    "# Train the model with adjusted batch size and epochs\n",
    "history = model.fit(X_train, y_train, epochs=15, validation_split=0.2, batch_size=1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Function to make predictions with flexible input using the trained model\n",
    "def predict_rent(input_data):\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    missing_cols = [col for col in features if col not in input_df.columns]\n",
    "    for col in missing_cols:\n",
    "        input_df[col] = [None]\n",
    "    \n",
    "    input_df = preprocessor.transform(input_df)\n",
    "    input_df = input_df.toarray() if hasattr(input_df, 'toarray') else input_df\n",
    "    return model.predict(input_df).flatten()[0]\n",
    "\n",
    "# Example prediction with flexible input\n",
    "example_input = {\n",
    "    'Location': ['HSR Layout'],\n",
    "    'No. of Bedroom': ['2 Bedroom'],\n",
    "    'Parking': ['Bike and Car'],\n",
    "    'Furnishing Status': ['Fully Furnished'],\n",
    "    'Total SqFt': [1000]\n",
    "}\n",
    "\n",
    "predicted_rent = predict_rent(example_input)\n",
    "print(f'Predicted Rent: {predicted_rent}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "046bc47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of predictions with error < 1000: 72.21%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test)\n",
    "\n",
    "# Calculate the percentage of predictions with an error margin of less than 1000\n",
    "percentage_within_1000 = (errors > 6000).mean() * 100\n",
    "\n",
    "print(f'Percentage of predictions with error < 1000: {percentage_within_1000:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f659fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Bedroom\n",
      "1 Bedroom     17532.032051\n",
      "2 Bedroom     29876.262626\n",
      "3 Bedroom     58972.222222\n",
      "4 Bedroom    176200.000000\n",
      "Name: Rent, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset for HSR Layout\n",
    "hsr_data = df[df['Location'] == 'HSR Layout']\n",
    "\n",
    "# Group by 'No. of Bedroom' and calculate the mean rent\n",
    "average_rent_by_bhk = hsr_data.groupby('No. of Bedroom')['Rent'].mean()\n",
    "\n",
    "print(average_rent_by_bhk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ee61693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['Age of Building', 'Water Supply', 'Rent', 'Transit Score',\n",
      "       'Smoking Allowed', 'Location', 'Bathroom', 'Non-Veg Allowed',\n",
      "       'Posted On', 'Parking', 'Property Type', 'Furnishing Status',\n",
      "       'No. of Bedroom', 'Facing', 'Gated Security', 'Deposit',\n",
      "       'Attached Bathroom', 'Livability Score', 'Balcony', 'URL',\n",
      "       'Drinking Allowed', 'Possession', 'Total SqFt', 'AC', 'Floor',\n",
      "       'Preferred Tenant', 'Room Type'],\n",
      "      dtype='object')\n",
      "Numeric features: ['Age of Building', 'Transit Score', 'Bathroom', 'Deposit', 'Livability Score', 'Total SqFt']\n",
      "Categorical features: ['Water Supply', 'Smoking Allowed', 'Location', 'Non-Veg Allowed', 'Posted On', 'Parking', 'Property Type', 'Furnishing Status', 'No. of Bedroom', 'Facing', 'Gated Security', 'Attached Bathroom', 'Balcony', 'URL', 'Drinking Allowed', 'Possession', 'AC', 'Floor', 'Preferred Tenant', 'Room Type']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: ['Smoking Allowed' 'Attached Bathroom' 'Drinking Allowed' 'AC' 'Room Type']. At least one non-missing value is needed for imputation with strategy='most_frequent'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 6184.012212028542\n",
      "Predicted Rent: 30060.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: ['Smoking Allowed' 'Attached Bathroom' 'Drinking Allowed' 'AC' 'Room Type']. At least one non-missing value is needed for imputation with strategy='most_frequent'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\impute\\_base.py:555: UserWarning: Skipping features without any observed values: ['Smoking Allowed' 'Attached Bathroom' 'Drinking Allowed' 'AC' 'Room Type']. At least one non-missing value is needed for imputation with strategy='most_frequent'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Define all features except 'Rent' and the target variable 'Rent'\n",
    "features = df.columns.drop(['Rent'])  # Ensure 'Rent' is not included as a feature\n",
    "target = 'Rent'\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Print columns to ensure consistency\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Handle missing values in features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Print out the features being used\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "# Define preprocessor with imputation and one-hot encoding for categorical features\n",
    "numeric_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Function to make predictions with flexible input\n",
    "def predict_rent(input_data):\n",
    "    # Convert input data to DataFrame, fill missing columns with NaNs\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    missing_cols = [col for col in features if col not in input_df.columns]\n",
    "    for col in missing_cols:\n",
    "        input_df[col] = [None]\n",
    "    \n",
    "    # Reorder columns to match the training data\n",
    "    input_df = input_df[features]\n",
    "    \n",
    "    # Predict using the trained pipeline\n",
    "    return pipeline.predict(input_df)\n",
    "\n",
    "# Example prediction with flexible input\n",
    "example_input = {\n",
    "    'Location': ['HSR Layout'],\n",
    "    'No. of Bedroom': ['2 Bedroom'],\n",
    "    'Parking': ['Bike and Car'],\n",
    "    'Furnishing Status': ['Fully Furnished'],\n",
    "    'Total SqFt': [1200]\n",
    "    # You can omit or add any feature; the model will handle it\n",
    "}\n",
    "\n",
    "predicted_rent = predict_rent(example_input)\n",
    "print(f'Predicted Rent: {predicted_rent[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a91b0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1872.6288379204893\n"
     ]
    }
   ],
   "source": [
    "### random forest best\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=['Rent'])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Add the Cost_per_SqFt column\n",
    "df['Cost_per_SqFt'] = df['Rent'] / df['Total SqFt']\n",
    "\n",
    "# Replace infinite values that might arise from division by zero\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Handle missing values in Cost_per_SqFt\n",
    "df['Cost_per_SqFt'] = df['Cost_per_SqFt'].fillna(df['Cost_per_SqFt'].median())\n",
    "\n",
    "# Handle missing values in other features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Define preprocessor with imputation, scaling, and one-hot encoding\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop(columns=['Rent'])  # Features include the new Cost_per_SqFt column\n",
    "y = df['Rent']\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a7436ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2193.2871066459247\n"
     ]
    }
   ],
   "source": [
    "### best using gradient boosting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=['Rent'])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Add the Cost_per_SqFt column\n",
    "df['Cost_per_SqFt'] = df['Rent'] / df['Total SqFt']\n",
    "\n",
    "# Replace infinite values that might arise from division by zero\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Handle missing values in Cost_per_SqFt\n",
    "df['Cost_per_SqFt'] = df['Cost_per_SqFt'].fillna(df['Cost_per_SqFt'].median())\n",
    "\n",
    "# Handle missing values in other features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Define preprocessor with imputation, scaling, and one-hot encoding\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop(columns=['Rent'])  # Features include the new Cost_per_SqFt column\n",
    "y = df['Rent']\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gb_model = GradientBoostingRegressor(random_state=0)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aabf7841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 14488.5596 - val_loss: 7104.2871\n",
      "Epoch 2/16\n",
      "314/314 [==============================] - 2s 8ms/step - loss: 5631.8267 - val_loss: 4684.5840\n",
      "Epoch 3/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 4358.3428 - val_loss: 4024.7209\n",
      "Epoch 4/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3871.5513 - val_loss: 3560.0315\n",
      "Epoch 5/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3521.8416 - val_loss: 3365.1545\n",
      "Epoch 6/16\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 3280.5723 - val_loss: 3284.4353\n",
      "Epoch 7/16\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 3169.7661 - val_loss: 3288.4968\n",
      "Epoch 8/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2935.3086 - val_loss: 3165.6926\n",
      "Epoch 9/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2767.8274 - val_loss: 3140.2996\n",
      "Epoch 10/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2640.9485 - val_loss: 3137.4219\n",
      "Epoch 11/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2596.0327 - val_loss: 3030.7373\n",
      "Epoch 12/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2539.0447 - val_loss: 3284.6572\n",
      "Epoch 13/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2446.3794 - val_loss: 3027.9333\n",
      "Epoch 14/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2297.6113 - val_loss: 3112.7385\n",
      "Epoch 15/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2328.1758 - val_loss: 3068.7791\n",
      "Epoch 16/16\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2327.2471 - val_loss: 3055.0615\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "Mean Absolute Error: 3757.9175723014623\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predicted Rent: 108.45211791992188\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=['Rent'])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Add the Cost_per_SqFt column\n",
    "df['Cost_per_SqFt'] = df['Rent'] / df['Total SqFt']\n",
    "\n",
    "# Replace infinite values that might arise from division by zero\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Handle missing values in Cost_per_SqFt\n",
    "df['Cost_per_SqFt'] = df['Cost_per_SqFt'].fillna(df['Cost_per_SqFt'].median())\n",
    "\n",
    "# Handle missing values in other features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Ensure 'Cost_per_SqFt' is included in numeric features\n",
    "if 'Cost_per_SqFt' not in numeric_features:\n",
    "    numeric_features.append('Cost_per_SqFt')\n",
    "\n",
    "# Define preprocessor with imputation, scaling, and one-hot encoding\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop(columns=['Rent'])  # Features include the new Cost_per_SqFt column\n",
    "y = df['Rent']\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert to dense array if it's still sparse\n",
    "X = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Convert y_train and y_test to NumPy arrays\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=16, validation_split=0.2, batch_size=10, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Function to make predictions with flexible input using the trained model\n",
    "def predict_rent(input_data):\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    missing_cols = [col for col in df.columns if col not in input_df.columns]\n",
    "    for col in missing_cols:\n",
    "        input_df[col] = [None]\n",
    "    \n",
    "    input_df = preprocessor.transform(input_df)\n",
    "    input_df = input_df.toarray() if hasattr(input_df, 'toarray') else input_df\n",
    "    return model.predict(input_df).flatten()[0]\n",
    "\n",
    "# Example prediction with flexible input\n",
    "example_input = {\n",
    "    'Location': ['HSR Layout'],\n",
    "    'No. of Bedroom': ['2 Bedroom'],\n",
    "    'Parking': ['Bike and Car'],\n",
    "    'Furnishing Status': ['Fully Furnished'],\n",
    "    'Total SqFt': [1000],\n",
    "    'Cost_per_SqFt': [1000/1000]  # Example value, should match calculated value\n",
    "}\n",
    "\n",
    "predicted_rent = predict_rent(example_input)\n",
    "print(f'Predicted Rent: {predicted_rent}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31466cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 14556.5986 - val_loss: 7145.8760\n",
      "Epoch 2/20\n",
      "314/314 [==============================] - 2s 8ms/step - loss: 5715.9224 - val_loss: 4615.1289\n",
      "Epoch 3/20\n",
      "314/314 [==============================] - 2s 8ms/step - loss: 4350.5732 - val_loss: 4046.8364\n",
      "Epoch 4/20\n",
      "314/314 [==============================] - 3s 8ms/step - loss: 3779.4602 - val_loss: 3788.9290\n",
      "Epoch 5/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3456.0920 - val_loss: 3528.4146\n",
      "Epoch 6/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3321.4089 - val_loss: 3386.6074\n",
      "Epoch 7/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 3066.6313 - val_loss: 3270.1860\n",
      "Epoch 8/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2965.4795 - val_loss: 3211.3242\n",
      "Epoch 9/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2902.7429 - val_loss: 3127.3689\n",
      "Epoch 10/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2768.5938 - val_loss: 3264.7898\n",
      "Epoch 11/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 2715.2300 - val_loss: 3206.4360\n",
      "Epoch 12/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2593.7913 - val_loss: 3231.0039\n",
      "Epoch 13/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 2475.7986 - val_loss: 3085.6147\n",
      "Epoch 14/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 2472.3025 - val_loss: 3084.5493\n",
      "Epoch 15/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 2364.0620 - val_loss: 3059.7288\n",
      "Epoch 16/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 2348.9878 - val_loss: 3141.1494\n",
      "Epoch 17/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 2326.8252 - val_loss: 3099.1182\n",
      "Epoch 18/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 2292.8682 - val_loss: 3173.9062\n",
      "Epoch 19/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 2221.5818 - val_loss: 3030.5864\n",
      "Epoch 20/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 2198.1116 - val_loss: 3091.9714\n",
      "31/31 [==============================] - 0s 5ms/step\n",
      "Mean Absolute Error: 3784.0964843252264\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted Rent: 9.092270851135254\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=['Rent'])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Add the Cost_per_SqFt column\n",
    "df['Cost_per_SqFt'] = df['Rent'] / df['Total SqFt']\n",
    "\n",
    "# Replace infinite values that might arise from division by zero\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Handle missing values in Cost_per_SqFt\n",
    "df['Cost_per_SqFt'] = df['Cost_per_SqFt'].fillna(df['Cost_per_SqFt'].median())\n",
    "\n",
    "# Handle missing values in other features\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Ensure 'Cost_per_SqFt' is included in numeric features\n",
    "if 'Cost_per_SqFt' not in numeric_features:\n",
    "    numeric_features.append('Cost_per_SqFt')\n",
    "\n",
    "# Update the pipeline to handle missing values in categorical features by imputing 'none'\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='none')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop(columns=['Rent'])  # Features include the new Cost_per_SqFt column\n",
    "y = df['Rent']\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert to dense array if it's still sparse\n",
    "X = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Convert y_train and y_test to NumPy arrays\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_split=0.2, batch_size=10, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Function to make predictions with flexible input using the trained model\n",
    "def predict_rent(input_data):\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    missing_cols = [col for col in df.columns if col not in input_df.columns]\n",
    "    for col in missing_cols:\n",
    "        input_df[col] = [None]\n",
    "    \n",
    "    input_df = preprocessor.transform(input_df)\n",
    "    input_df = input_df.toarray() if hasattr(input_df, 'toarray') else input_df\n",
    "    return model.predict(input_df).flatten()[0]\n",
    "\n",
    "# Example prediction with flexible input\n",
    "example_input = {\n",
    "    'Location': ['HSR Layout'],\n",
    "    'No. of Bedroom': ['2 Bedroom'],\n",
    "    'Parking': ['Bike and Car'],\n",
    "    'Furnishing Status': ['Fully Furnished'],\n",
    "    'Total SqFt': [1000],\n",
    "    'Cost_per_SqFt': [1000/1000]  # Example value, should match calculated value\n",
    "}\n",
    "\n",
    "predicted_rent = predict_rent(example_input)\n",
    "print(f'Predicted Rent: {predicted_rent}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "758fa94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of predictions with error < 1000: 67.58%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test)\n",
    "\n",
    "# Calculate the percentage of predictions with an error margin of less than 1000\n",
    "percentage_within_1000 = (errors < 500).mean() * 100\n",
    "\n",
    "print(f'Percentage of predictions with error < 1000: {percentage_within_1000:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e49947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df['Property Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31792d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age of Building', 'Water Supply', 'Rent', 'Transit Score',\n",
       "       'Smoking Allowed', 'Location', 'Bathroom', 'Non-Veg Allowed',\n",
       "       'Posted On', 'Parking', 'Property Type', 'Furnishing Status',\n",
       "       'No. of Bedroom', 'Facing', 'Gated Security', 'Deposit',\n",
       "       'Attached Bathroom', 'Livability Score', 'Balcony', 'URL',\n",
       "       'Drinking Allowed', 'Possession', 'Total SqFt', 'AC', 'Floor',\n",
       "       'Preferred Tenant', 'Room Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9de438bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Apartment', 'Independent House/villa', 'Gated Community',\n",
       "       'Independent Floor/builder Floor', 'Standalone Building'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73bf6b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age of Building      4026\n",
       "Water Supply         1868\n",
       "Rent                    0\n",
       "Transit Score         189\n",
       "Smoking Allowed      4903\n",
       "Location                0\n",
       "Bathroom                1\n",
       "Non-Veg Allowed         0\n",
       "Posted On               0\n",
       "Parking               444\n",
       "Property Type           0\n",
       "Furnishing Status       0\n",
       "No. of Bedroom          1\n",
       "Facing               2070\n",
       "Gated Security          0\n",
       "Deposit                 0\n",
       "Attached Bathroom    4903\n",
       "Livability Score      189\n",
       "Balcony              2699\n",
       "URL                     0\n",
       "Drinking Allowed     4903\n",
       "Possession              0\n",
       "Total SqFt              0\n",
       "AC                   4903\n",
       "Floor                   0\n",
       "Preferred Tenant        0\n",
       "Room Type            4903\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "95d0bf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Independent House/villa' 'Apartment' 'Independent Floor/builder Floor']\n"
     ]
    }
   ],
   "source": [
    "filtered_data = df[(df['Location'] == 'HSR Layout') & (df['No. of Bedroom'] == '2 Bedroom')]\n",
    "\n",
    "# Print the filtered data\n",
    "print(filtered_data['Property Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8aedfb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age of Building      4026\n",
       "Water Supply         1868\n",
       "Rent                    0\n",
       "Transit Score         189\n",
       "Smoking Allowed      4903\n",
       "Location                0\n",
       "Bathroom                1\n",
       "Non-Veg Allowed         0\n",
       "Posted On               0\n",
       "Parking               444\n",
       "Property Type           0\n",
       "Furnishing Status       0\n",
       "No. of Bedroom          1\n",
       "Facing               2070\n",
       "Gated Security          0\n",
       "Deposit                 0\n",
       "Attached Bathroom    4903\n",
       "Livability Score      189\n",
       "Balcony              2699\n",
       "URL                     0\n",
       "Drinking Allowed     4903\n",
       "Possession              0\n",
       "Total SqFt              0\n",
       "AC                   4903\n",
       "Floor                   0\n",
       "Preferred Tenant        0\n",
       "Room Type            4903\n",
       "Cost_per_SqFt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6258254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Drop rows where target or 'No. of Bedroom' is missing\n",
    "df = df.dropna(subset=['Rent', 'No. of Bedroom'])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Add the Cost_per_SqFt column\n",
    "df['Cost_per_SqFt'] = df['Rent'] / df['Total SqFt']\n",
    "\n",
    "# Replace infinite values that might arise from division by zero\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Handle missing values in Cost_per_SqFt\n",
    "df['Cost_per_SqFt'] = df['Cost_per_SqFt'].fillna(df['Cost_per_SqFt'].median())\n",
    "\n",
    "# Drop columns with all missing values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Custom Transformer for grouped imputation\n",
    "class GroupImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_cols, impute_col):\n",
    "        self.group_cols = group_cols\n",
    "        self.impute_col = impute_col\n",
    "        self.fill_values = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill_values = (\n",
    "            X.groupby(self.group_cols)[self.impute_col]\n",
    "            .agg(lambda x: x.value_counts().index[0] if not x.isnull().all() else np.nan)\n",
    "            .to_dict()\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for key, value in self.fill_values.items():\n",
    "            mask = (X[self.group_cols[0]] == key[0]) & (X[self.group_cols[1]] == key[1])\n",
    "            X.loc[mask, self.impute_col] = X.loc[mask, self.impute_col].fillna(value)\n",
    "        return X\n",
    "\n",
    "# Apply grouped imputation for categorical variables\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col not in ['Location', 'No. of Bedroom']:  # Exclude grouping columns themselves\n",
    "        imputer = GroupImputer(group_cols=['Location', 'No. of Bedroom'], impute_col=col)\n",
    "        df = imputer.fit_transform(df)\n",
    "\n",
    "# Additional step: Impute any remaining missing values in numeric columns\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "imputer_numeric = SimpleImputer(strategy='mean')\n",
    "df[numeric_features] = imputer_numeric.fit_transform(df[numeric_features])\n",
    "\n",
    "# Prepare features and target\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Ensure 'Cost_per_SqFt' is included in numeric features\n",
    "if 'Cost_per_SqFt' not in numeric_features:\n",
    "    numeric_features.append('Cost_per_SqFt')\n",
    "\n",
    "# Define preprocessor with scaling and one-hot encoding\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop(columns=['Rent'])  # Features include the new Cost_per_SqFt column\n",
    "y = df['Rent']\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bef3fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Best version 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'realtor_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the Rent column by removing non-numeric characters\n",
    "df['Rent'] = df['Rent'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "df['Rent'] = pd.to_numeric(df['Rent'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'Rent' is greater than 10,000,000 in \"HSR Layout\"\n",
    "df = df[~((df['Location'] == 'HSR Layout') & (df['Rent'] > 10000000))]\n",
    "\n",
    "# Drop rows where target or 'No. of Bedroom' is missing\n",
    "df = df.dropna(subset=['Rent', 'No. of Bedroom'])\n",
    "\n",
    "# Handle non-numeric 'Age of Building' by converting to a numeric value\n",
    "df['Age of Building'] = df['Age of Building'].replace('Newly Constructed', 0)\n",
    "df['Age of Building'] = pd.to_numeric(df['Age of Building'], errors='coerce')\n",
    "\n",
    "# Add the Cost_per_SqFt column\n",
    "df['Cost_per_SqFt'] = df['Rent'] / df['Total SqFt']\n",
    "\n",
    "# Replace infinite values that might arise from division by zero\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Handle missing values in Cost_per_SqFt\n",
    "df['Cost_per_SqFt'] = df['Cost_per_SqFt'].fillna(df['Cost_per_SqFt'].median())\n",
    "\n",
    "# Drop columns with all missing values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Custom Transformer for grouped imputation\n",
    "class GroupImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_cols, impute_col):\n",
    "        self.group_cols = group_cols\n",
    "        self.impute_col = impute_col\n",
    "        self.fill_values = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill_values = (\n",
    "            X.groupby(self.group_cols)[self.impute_col]\n",
    "            .agg(lambda x: x.value_counts().index[0] if not x.isnull().all() else np.nan)\n",
    "            .to_dict()\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for key, value in self.fill_values.items():\n",
    "            mask = (X[self.group_cols[0]] == key[0]) & (X[self.group_cols[1]] == key[1])\n",
    "            X.loc[mask, self.impute_col] = X.loc[mask, self.impute_col].fillna(value)\n",
    "        return X\n",
    "\n",
    "# Apply grouped imputation for categorical variables\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col not in ['Location', 'No. of Bedroom']:  # Exclude grouping columns themselves\n",
    "        imputer = GroupImputer(group_cols=['Location', 'No. of Bedroom'], impute_col=col)\n",
    "        df = imputer.fit_transform(df)\n",
    "\n",
    "# Additional step: Impute any remaining missing values in numeric columns\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "imputer_numeric = SimpleImputer(strategy='mean')\n",
    "df[numeric_features] = imputer_numeric.fit_transform(df[numeric_features])\n",
    "\n",
    "# Prepare features and target\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Rent' from numeric features if it was mistakenly included\n",
    "if 'Rent' in numeric_features:\n",
    "    numeric_features.remove('Rent')\n",
    "\n",
    "# Ensure 'Cost_per_SqFt' is included in numeric features\n",
    "if 'Cost_per_SqFt' not in numeric_features:\n",
    "    numeric_features.append('Cost_per_SqFt')\n",
    "\n",
    "# Define preprocessor with scaling and one-hot encoding\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop(columns=['Rent'])  # Features include the new Cost_per_SqFt column\n",
    "y = df['Rent']\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0518a0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4903, 23)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "095abcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Absolute Error: 1676.3486646279307\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "rf_model = RandomForestRegressor(random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f'Random Forest - Mean Absolute Error: {mae_rf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "94df99c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of predictions with error < 1000: 92.76%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred_rf - y_test)\n",
    "\n",
    "# Calculate the percentage of predictions with an error margin of less than 1000\n",
    "percentage_within_1000 = (errors < 2000).mean() * 100\n",
    "\n",
    "print(f'Percentage of predictions with error < 1000: {percentage_within_1000:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b921477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Mean Absolute Error: 1983.5221368649113\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Model\n",
    "gb_model = GradientBoostingRegressor(random_state=0)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "print(f'Gradient Boosting - Mean Absolute Error: {mae_gb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d77209d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of predictions with error < 1000: 59.94%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred_gb - y_test)\n",
    "\n",
    "# Calculate the percentage of predictions with an error margin of less than 1000\n",
    "percentage_within_1000 = (errors < 1000).mean() * 100\n",
    "\n",
    "print(f'Percentage of predictions with error < 1000: {percentage_within_1000:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0351e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
