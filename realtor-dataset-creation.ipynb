{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9339d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with progress monitoring\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException, StaleElementReferenceException\n",
    "from requests.exceptions import ProxyError, SSLError\n",
    "\n",
    "# List of user agents\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:89.0) Gecko/20100101 Firefox/89.0',\n",
    "    'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.64',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 OPR/77.0.4054.90',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36 OPR/77.0.4054.90',\n",
    "    'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Mobile/15E148 Safari/604.1',\n",
    "    'Mozilla/5.0 (Linux; Android 10; SM-G975F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Mobile Safari/537.36'\n",
    "]\n",
    "\n",
    "def configure_driver(user_agent):\n",
    "    options = Options()\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    return driver\n",
    "\n",
    "def extract_data(driver):\n",
    "    data = {}\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "        time.sleep(1)  # Wait additional time for the page to fully load\n",
    "        \n",
    "        try:\n",
    "            rent = driver.find_element(By.ID, 'rent-maintenance').text.replace('₹', '').replace('/M', '').replace(',', '').strip()\n",
    "            data['Rent'] = rent\n",
    "        except NoSuchElementException:\n",
    "            data['Rent'] = None\n",
    "        \n",
    "        try:\n",
    "            total_sqft = driver.find_element(By.ID, 'square-ft').text.replace(',', '').strip()\n",
    "            data['Total SqFt'] = total_sqft\n",
    "        except NoSuchElementException:\n",
    "            data['Total SqFt'] = None\n",
    "        \n",
    "        try:\n",
    "            deposit = driver.find_element(By.ID, 'emi').text.replace('₹', '').replace(',', '').strip()\n",
    "            data['Deposit'] = deposit\n",
    "        except NoSuchElementException:\n",
    "            data['Deposit'] = None\n",
    "        \n",
    "        try:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, 'div.nb__3Z_gh')\n",
    "            for elem in elements:\n",
    "                key = elem.find_element(By.CSS_SELECTOR, 'h5.nb__X_Hde').text.strip()\n",
    "                value = elem.find_element(By.CSS_SELECTOR, 'h4.nb__GDnvX').text.strip()\n",
    "                data[key] = value\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, 'div.nb__3ocPe')\n",
    "            for elem in elements:\n",
    "                key = elem.find_element(By.CSS_SELECTOR, 'h5.nb__1IoiM').text.strip()\n",
    "                value = elem.find_element(By.CSS_SELECTOR, 'h5.font-semi-bold.nb__1IoiM').text.strip()\n",
    "                data[key] = value\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            livability_score = driver.find_element(By.CSS_SELECTOR, 'div[data-original-title=\"Livabilty Score is a measure of proximity of the property to essential facilities and amenities on a scale of 0 to 10\"] .nb__3lxrH').text.strip()\n",
    "            data['Livability Score'] = livability_score\n",
    "        except NoSuchElementException:\n",
    "            data['Livability Score'] = None\n",
    "        \n",
    "        try:\n",
    "            transit_score = driver.find_element(By.CSS_SELECTOR, 'div[data-original-title=\"Transit Score is a measure of how well a property is served by public transit on a scale from 0 to 10\"] .nb__3lxrH').text.strip()\n",
    "            data['Transit Score'] = transit_score\n",
    "        except NoSuchElementException:\n",
    "            data['Transit Score'] = None\n",
    "        \n",
    "    except TimeoutException as e:\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_url(driver, location, url, retries=3):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "            \n",
    "            time.sleep(1)  # Wait for the page to load\n",
    "            \n",
    "            # Scroll down to load all elements\n",
    "            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            data = extract_data(driver)\n",
    "            data['URL'] = url\n",
    "            data['Location'] = location\n",
    "            return data\n",
    "        except (WebDriverException, TimeoutException, NoSuchElementException, StaleElementReferenceException, ProxyError, SSLError) as e:\n",
    "            print(f\"Error processing URL {url}: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                print(f\"Retrying... ({attempt + 1}/{retries})\")\n",
    "            else:\n",
    "                print(f\"Failed after {retries} attempts\")\n",
    "    return None\n",
    "\n",
    "def save_intermediate_data(data, processed_urls, data_filename='property_data.json', progress_filename='processed_urls.json'):\n",
    "    with open(data_filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    with open(progress_filename, 'w') as f:\n",
    "        json.dump(processed_urls, f, indent=4)\n",
    "\n",
    "def load_processed_urls(filename='processed_urls.json'):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            return set(json.load(f))\n",
    "    return set()\n",
    "\n",
    "def process_urls(url_list, urls_per_session=10, save_interval=5):\n",
    "    all_data = []\n",
    "    processed_urls = load_processed_urls()\n",
    "    user_agent_index = 0\n",
    "    \n",
    "    for i in range(0, len(url_list), urls_per_session):\n",
    "        batch = url_list[i:i+urls_per_session]\n",
    "        user_agent = user_agents[user_agent_index]\n",
    "        user_agent_index = (user_agent_index + 1) % len(user_agents)\n",
    "        \n",
    "        driver = configure_driver(user_agent)\n",
    "        try:\n",
    "            for location, url in batch:\n",
    "                if url in processed_urls:\n",
    "                    continue\n",
    "                \n",
    "                data = process_url(driver, location, url)\n",
    "                if data:\n",
    "                    all_data.append(data)\n",
    "                    processed_urls.add(url)\n",
    "            \n",
    "            # Save data at regular intervals\n",
    "            if (i // urls_per_session + 1) % save_interval == 0:\n",
    "                save_intermediate_data(all_data, list(processed_urls))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {e}\")\n",
    "        finally:\n",
    "            driver.quit()\n",
    "    \n",
    "    # Final save of the collected data\n",
    "    save_intermediate_data(all_data, list(processed_urls))\n",
    "    return all_data\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Load URLs from JSON file\n",
    "url_file = 'urls_5th_aug.json'\n",
    "with open(url_file, 'r') as file:\n",
    "    url_list = json.load(file)\n",
    "\n",
    "# Process the URLs and save the data\n",
    "data = process_urls(url_list)\n",
    "save_to_json(data, 'property_data.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c526067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load JSON data from the file\n",
    "with open('property_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Identify all unique keys in the JSON data\n",
    "all_keys = set()\n",
    "for item in data:\n",
    "    all_keys.update(item.keys())\n",
    "\n",
    "# Create a DataFrame with all unique keys\n",
    "df = pd.DataFrame(columns=list(all_keys))\n",
    "\n",
    "# Populate the DataFrame\n",
    "for item in data:\n",
    "    df = df.append(item, ignore_index=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('realtor_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43240689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
